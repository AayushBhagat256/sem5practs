import numpy as np

def perceptron_train(input_size, training_data, labels, learning_rate=0.1, epochs=100):
    weights = np.zeros(input_size + 1)

    def activation(x):
        return 1 if x >= 0 else 0

    def predict(inputs):
        summation = np.dot(inputs, weights[1:]) + weights[0]
        return activation(summation)

    for _ in range(epochs):
        for inputs, label in zip(training_data, labels):
            prediction = predict(inputs)
            weights[1:] += learning_rate * (label - prediction) * inputs
            weights[0] += learning_rate * (label - prediction)

    return weights

# Example usage:
# Each pattern is represented as a list of features. Here, we use a simple representation of 'L' and 'M'.
# 'L' pattern: [1, 1, 1, 0, 1, 0, 0, 1, 0]
# 'M' pattern: [1, 1, 1, 1, 1, 0, 0, 1, 0]

# Training data
training_data = np.array([[1, 1, 1, 0, 1, 0, 0, 1, 0], [1, 1, 1, 1, 1, 0, 0, 1, 0]])
# Corresponding labels: 1 for 'L', 0 for 'M'
labels = np.array([1, 0])

# Initialize the perceptron
input_size = len(training_data[0])
learned_weights = perceptron_train(input_size, training_data, labels)

# Test the perceptron
test_pattern = np.array([1, 1, 1, 0, 1, 0, 0, 1, 0])
prediction = 1 if np.dot(test_pattern, learned_weights[1:]) + learned_weights[0] >= 0 else 0

if prediction == 1:
    print("The pattern is 'L'")
else:
    print("The pattern is 'M'")
